<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Raft协议介绍</title>
    <link href="/raft/"/>
    <url>/raft/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul><li>Paxos一直是分布式协议的标准，但是Paxos难于理解，更难以实现。</li><li>Google的分布式锁系统Chubby作为Paxos实现曾经遭遇到很多坑。</li><li>Raft，它是一个为真实世界应用建立的协议，相比Paxos主要注重协议的落地性和可理解性。</li></ul><h2 id="Raft选主"><a href="#Raft选主" class="headerlink" title="Raft选主"></a>Raft选主</h2><h3 id="选主过程"><a href="#选主过程" class="headerlink" title="选主过程"></a>选主过程</h3><p>Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。</p><p>每一个follower都有一个时钟，是一个随机的值，表示的是follower等待成为leader的时间，谁的时钟先跑完，则发起leader选举。</p><p>Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：</p><ul><li>赢得了多数的选票，成功选举为Leader；</li><li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li><li>没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。</li></ul><h3 id="选主限制"><a href="#选主限制" class="headerlink" title="选主限制"></a>选主限制</h3><p>在Raft协议中，所有的日志条目都只会从Leader节点往Follower节点写入，且Leader节点上的日志只会增加，绝对不会删除或者覆盖。</p><p>这意味着Leader节点必须包含所有已经提交的日志，即能被选举为Leader的节点一定需要包含所有的已经提交的日志。因为日志只会从Leader向Follower传输，所以如果被选举出的Leader缺少已经Commit的日志，那么这些已经提交的日志就会丢失，显然这是不符合要求的。</p><p>即能被选举成为Leader的节点，一定包含了所有已经提交的日志条目。</p><h2 id="Raft日志同步"><a href="#Raft日志同步" class="headerlink" title="Raft日志同步"></a>Raft日志同步</h2><h3 id="日志同步过程"><a href="#日志同步过程" class="headerlink" title="日志同步过程"></a>日志同步过程</h3><p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。</p><ul><li>客户端的每一个请求都包含被复制状态机执行的指令。</li><li>leader把这个指令作为一条新的日志条目添加到日志中，然后并行发起 RPC 给其他的服务器，让他们复制这条信息。</li><li>假如这条日志被安全的复制，领导人就应用这条日志到自己的状态机中，并返回给客户端。</li><li>如果 follower 宕机或者运行缓慢或者丢包，leader会不断的重试，直到所有的 follower 最终都复制了所有的日志条目。</li></ul><h3 id="日志组成"><a href="#日志组成" class="headerlink" title="日志组成"></a>日志组成</h3><p>日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term）和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。</p><h3 id="日志一致性"><a href="#日志一致性" class="headerlink" title="日志一致性"></a>日志一致性</h3><h4 id="日志复制的两条保证"><a href="#日志复制的两条保证" class="headerlink" title="日志复制的两条保证"></a>日志复制的两条保证</h4><ul><li><p>如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的（原因：leader 最多在一个任期里的一个日志索引位置创建一条日志条目，日志条目在日志的位置从来不会改变）。</p></li><li><p>如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的（原因：每次 RPC 发送附加日志时，leader 会把这条日志条目的前面的日志的下标和任期号一起发送给 follower，如果 follower 发现和自己的日志不匹配，那么就拒绝接受这条日志，这个称之为一致性检查）。</p></li></ul><h4 id="日志的不正常情况"><a href="#日志的不正常情况" class="headerlink" title="日志的不正常情况"></a>日志的不正常情况</h4><p>一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致：旧的Leader可能没有完全复制完日志中的所有条目。</p><h4 id="如何保证日志的正常复制"><a href="#如何保证日志的正常复制" class="headerlink" title="如何保证日志的正常复制"></a>如何保证日志的正常复制</h4><p>Leader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。Leader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。</p><p>具体的操作是：Leader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位置点（基于上述的两条保证），然后向后逐条覆盖Followers在该位置之后的条目。</p><p>总结一下就是：当 leader 和 follower 日志冲突的时候，leader 将校验 follower 最后一条日志是否和 leader 匹配，如果不匹配，将递减查询，直到匹配，匹配后，删除冲突的日志。这样就实现了主从日志的一致性。</p><h2 id="Raft安全性"><a href="#Raft安全性" class="headerlink" title="Raft安全性"></a>Raft安全性</h2><p>Raft增加了如下两条限制以保证安全性：</p><ul><li>拥有最新的已提交的log entry的Follower才有资格成为leader。</li><li>Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。</li></ul><h2 id="Raft日志压缩"><a href="#Raft日志压缩" class="headerlink" title="Raft日志压缩"></a>Raft日志压缩</h2><p>在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃（以前的数据已经落盘了）。</p><p>每个副本独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。</p><p>Snapshot中包含以下内容：</p><ul><li>日志元数据，最后一条已提交的 log entry的 log index和term。这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。</li><li>系统当前状态。</li></ul><p>当Leader要发给某个日志落后太多的Follower的log entry被丢弃，Leader会将snapshot发给Follower。或者当新加进一台机器时，也会发送snapshot给它。发送snapshot使用InstalledSnapshot RPC。</p><p>做snapshot既不要做的太频繁，否则消耗磁盘带宽， 也不要做的太不频繁，否则一旦节点重启需要回放大量日志，影响可用性。推荐当日志达到某个固定的大小做一次snapshot。</p><p>做一次snapshot可能耗时过长，会影响正常日志同步。可以通过使用copy-on-write技术避免snapshot过程影响正常日志同步。</p><h2 id="Raft成员变更"><a href="#Raft成员变更" class="headerlink" title="Raft成员变更"></a>Raft成员变更</h2><h3 id="常规处理成员变更存在的问题"><a href="#常规处理成员变更存在的问题" class="headerlink" title="常规处理成员变更存在的问题"></a>常规处理成员变更存在的问题</h3><p>我们先将成员变更请求当成普通的写请求，由领导者得到多数节点响应后，每个节点提交成员变更日志，将从旧成员配置（Cold）切换到新成员配置（Cnew）。但每个节点提交成员变更日志的时刻可能不同，这将造成各个服务器切换配置的时刻也不同，这就有可能选出两个领导者，破坏安全性。</p><p>考虑以下这种情况：集群配额从 3 台机器变成了 5 台，可能存在这样的一个时间点，两个不同的领导者在同一个任期里都可以被选举成功（双主问题），一个是通过旧的配置，一个通过新的配置。</p><p>简而言之，成员变更存在的问题是增加或者减少的成员太多了，导致旧成员组和新成员组没有交集，因此出现了双主。</p><h2 id="Raft节点接口"><a href="#Raft节点接口" class="headerlink" title="Raft节点接口"></a>Raft节点接口</h2><h2 id="Raft-Corner-Case"><a href="#Raft-Corner-Case" class="headerlink" title="Raft Corner Case"></a>Raft Corner Case</h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><p><a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf" target="_blank" rel="noopener">Raft论文</a></p></li><li><p><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">Raft动画</a></p></li><li><p><a href="https://network.fasionchan.com/zh_CN/latest/translations/raft-paper.html" target="_blank" rel="noopener">博客：寻找好理解的共识算法</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CAP 定理介绍</title>
    <link href="/cap-theory/"/>
    <url>/cap-theory/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在互联网行业飞速发展的21世纪，分布式系统正变得越来越重要，大型互联网公司如 Google, Amazon, MicroSoft, Alibaba, Tencent 等之所以被认为技术很厉害，很大程度上是因为其后台十分强悍，而这些后台一定是由若干个大的分布式系统组成的，因此理解分布式系统的运行原理对于程序员有非常重要的意义。</p><p>CAP定理是分布式系统方向一个比较宽泛但很重要的基本定理，也可以作为理解分布式系统的起点。这篇博客将详细介绍CAP定理并简单证明，最后谈一谈CAP定理在工业界的应用。</p><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>2000年，柏克莱加州大学(University of California, Berkeley)的计算机科学家Eric Brewer在分布式计算原则研讨会(Symposium on Principles of Distributed Computing)提出，分布式系统有三个指标。</p><ul><li>Consistency</li><li>Availability</li><li>Partition tolerance</li></ul><p>它们的第一个字母分别是C、A、P。</p><p>Eric Brewer说，这三个指标不可能同时做到。这个结论就叫做CAP定理。</p><p>需要注意的是，尽管我们常说某个系统能够满足CAP属性中的2个，但并不是必须满足2个，许多系统只具有0或1个CAP属性。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h3><p>我们知道ACID中事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行前后，数据库都必须处于一致性状态。也就是说，事务的执行结果必须是使数据库从一个一致性状态转变到另一个一致性状态。</p><p>和ACID中的一致性不同，分布式环境中的一致性是指数据在多个副本之间是否能够保持一致的特性。</p><p>分布式系统中，数据一般会存在不同节点的副本中，如果对第一个节点的数据成功进行了更新操作，而第二个节点上的数据却没有得到相应更新，这时候读取第二个节点的数据依然是更新前的数据，即脏数据，这就是分布式系统数据不一致的情况。</p><p>在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都能读取到最新的值，那么这样的系统就被认为具有强一致性（或严格的一致性）。</p><h3 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h3><p>可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果，如果超过了这个时间范围，那么系统就被认为是不可用的。</p><p>“有限的时间内”是在系统的运行指标，不同系统会有差别。例如搜索引擎通常在0.5秒内需要给出用户检索结果。</p><p>“返回结果”是可用性的另一个重要指标，它要求系统完成对用户请求的处理后，返回一个正常的响应结果，要明确的反映出对请求处理的成功或失败。如果返回的结果是系统错误，比如”OutOfMemory”等报错信息，则认为此时系统是不可用的。</p><h3 id="Partition-Tolerance"><a href="#Partition-Tolerance" class="headerlink" title="Partition Tolerance"></a>Partition Tolerance</h3><p>一个分布式系统中，节点组成的网络本来应该是连通的。然而可能因为某些故障，使得有些节点之间不连通了，整个网络就分成了几块区域，而数据就散布在了这些不连通的区域中，这就叫分区。</p><p>当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。</p><p>提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项仍然能在其他区中读取，容忍性就提高了。然而，把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。</p><p>总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。</p><h2 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h2><h3 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h3><p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。</p><h3 id="详细证明"><a href="#详细证明" class="headerlink" title="详细证明"></a>详细证明</h3><p><img src="http://q5ijnj5w7.bkt.clouddn.com/cap_base.png" srcset="/img/loading.gif" alt=""></p><p>我们现在有两个网络N1和N2，每个网络中都存在一个服务用于从db获取数据，初始状态下，db中存储的数据都是V0。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/cap_p.png" srcset="/img/loading.gif" alt=""></p><p>正常情况下，在网络N1通过服务A更新V0到V1，更新成功后发送消息M使N2 db中的V0变为V1，此时我们通过服务B获取数据时，获取到V1。</p><pre><code>此时满足CA，没有分区故不满足P。</code></pre><p><img src="http://q5ijnj5w7.bkt.clouddn.com/cap_withoutp.png" srcset="/img/loading.gif" alt=""></p><p>但是一旦发生了网络分区，此时我们通过服务A更新数据到V1后，由于网络错误，V1值同步不到N2网络中去，此时我们调用服务B去请求数据的时候，我们必须从C和A选一个，如果选择C，我们需要等到数据同步到 N2，但是从服务B获取数据肯定是失败了，失去了A。如果选择A，那么从B我们获取到的数据不是最新的，失去了C。</p><pre><code>此时有分区故满足P，CA只能满足一个。</code></pre><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="取舍策略"><a href="#取舍策略" class="headerlink" title="取舍策略"></a>取舍策略</h3><h4 id="CP-without-A"><a href="#CP-without-A" class="headerlink" title="CP without A"></a>CP without A</h4><p>如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。</p><p>一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。</p><p>设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。</p><p>无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？</p><p>ZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。</p><h4 id="AP-wihtout-C"><a href="#AP-wihtout-C" class="headerlink" title="AP wihtout C"></a>AP wihtout C</h4><p>要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。</p><p>这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。</p><p>你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。</p><p>但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。</p><p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。</p><h4 id="CA-without-P"><a href="#CA-without-P" class="headerlink" title="CA without P"></a>CA without P</h4><p>这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。</p><p>比如我们熟知的关系型数据库，如Mysql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。</p><p>其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到：</p><blockquote><p>如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。</p></blockquote><p>从Google的经验中可以得到的结论是，一直以来我们可能被CAP理论蒙蔽了双眼，CAP三者之间并不对称，C和A不是P的原因（P不能和CA trade-off，CP和AP中不存在tradeoff，tradeoff在CA之间）。提高一个系统的抗毁能力或者说提高P（分区容忍能力）是通过提高基础设施的稳定性来获得的，而不是通过降低C和A来获得的。也就说牺牲C和A也不能提高P。</p><p>所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。P提升的越好，CA同时满足就越有可能。</p><h3 id="业界应用分析"><a href="#业界应用分析" class="headerlink" title="业界应用分析"></a>业界应用分析</h3><table><thead><tr><th>应用</th><th>类型</th><th>解释</th></tr></thead><tbody><tr><td>Mysql</td><td>CA</td><td>主从模式为AP</td></tr><tr><td>Spanner</td><td>CA/CP</td><td>技术实现是CP但号称是CA，宣称CA系统并不意味着100％的可用性</td></tr><tr><td>分布式协议-Raft/ZAB/Paxos</td><td>CP</td><td>在分区后，对于A，只有分区内节点大于quorum才对外服务</td></tr><tr><td>分布式事务-2PC</td><td>CP</td><td>锁住资源,该资源其他请求阻塞</td></tr><tr><td>分布式事务-TCC</td><td>AP</td><td>最终一致性</td></tr><tr><td>分布式事务-最大努力尝试</td><td>AP</td><td>最终一致性</td></tr><tr><td>DNS服务</td><td>AP</td><td>最终一致性</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，因此分区容错性也就成为了一个分布式系统必然要面对的问题，那么就只能在C和A之间进行取舍。</p><p>对于某些安全性要求极高的项目，比如银行的转账系统，涉及到金钱的对于数据一致性不能做出一丝的让步，C必须保证，出现网络故障的话，宁可停止服务，也不能冒着出错误的风险继续提供服务。</p><p>对于网站，DNS服务等，其内容的实时性不是特别严格，则可以牺牲一定的一致性，保证最高的可用性是最好的选择。</p><p>个人认为，CAP定理的核心在于，在网络分区的情况下，我们需要对C和A做出相应的妥协，我们不可能完全满足CA，但是我们可以合理控制C和A之间的比例让我们的应用/中间件正常提供服务，同时也尽量提升基础设施的稳定性来保障P。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>《Spanner，真时，CAP理论》是 Google VP，CAP理论之父在情人节当天撰写的，主要介绍了Google的Spanner数据库的真时（TrueTime）服务和CA特性，以及结合CAP理论的一些思考，建议阅读，阅读Spanner论文后阅读更佳。</p><ul><li><p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45855.pdf" target="_blank" rel="noopener">《Spanner，真时，CAP理论》</a></p></li><li><p><a href="https://toutiao.io/posts/zdqrx0/preview" target="_blank" rel="noopener">《Spanner，真时，CAP理论》中文</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iTerm2快捷键介绍</title>
    <link href="/iTerm2-hotkeys/"/>
    <url>/iTerm2-hotkeys/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>iTerm2是MacOS独有的终端工具，其有许多快捷键可以使用。为了便于开发并节约之后再次在搜索引擎上查询的时间成本，特写此博客以供自己日后查看。</p><h2 id="快捷键介绍"><a href="#快捷键介绍" class="headerlink" title="快捷键介绍"></a>快捷键介绍</h2><h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><ul><li>新建标签：Command + T</li><li>关闭标签：Command + W</li><li>切换标签：Command + 数字 或 Command + 左右方向键</li></ul><h3 id="分屏"><a href="#分屏" class="headerlink" title="分屏"></a>分屏</h3><ul><li>垂直分屏：Command + D</li><li>水平分屏：Command + Shift + D</li><li>切换屏幕：Command + Option + 方向键 或 Command + [ / ]</li></ul><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><ul><li>局部搜索(包含单个终端)：Command + F</li><li>全局搜索(包含所有Tab)：Command + Option + E</li><li>搜索历史指令：Ctrl + R</li></ul><h3 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h3><ul><li>查看历史命令：Command + ;</li><li>查看剪贴板历史：Command + Shift + H</li><li>上一条命令：Ctrl + P 或 上方向键</li></ul><h3 id="单行"><a href="#单行" class="headerlink" title="单行"></a>单行</h3><ul><li>光标到行首：Ctrl + A</li><li>光标到行尾：Ctrl + E</li><li>删除当前行：Ctrl + U</li><li>删除当前光标的字符：Ctrl + D</li><li>删除光标之前的字符：Ctrl + H</li><li>删除光标之前的单词：Ctrl + W</li><li>删除到文本末尾：Ctrl + K</li></ul><h3 id="内容大小"><a href="#内容大小" class="headerlink" title="内容大小"></a>内容大小</h3><ul><li>放大终端：Command + +</li><li>缩小终端：Command + - </li></ul><h3 id="常用快捷功能"><a href="#常用快捷功能" class="headerlink" title="常用快捷功能"></a>常用快捷功能</h3><ul><li>清屏：Command + R 或 Crtl + L</li><li>切换全屏：Command + Enter</li><li>选中即复制：在iTerm2界面，选择了一行就已经复制了</li></ul>]]></content>
    
    
    <categories>
      
      <category>开发工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的高效Macbook工作环境配置</title>
    <link href="/mac-configuration/"/>
    <url>/mac-configuration/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>工欲善其事，必先利其器，工具永远都是用来解决问题的，没必要为了工具而工具，一切工具都是为了能快速准确的完成工作和学习任务而服务。</p><p>我呢，在使用了Windows，Ubuntu和MacOS三种操作系统之后。结合种种体验和踩坑，最终还是觉得MacOS更舒适一点。每个人都有每个人的看法，每个人都有每个人的舒适点，MacOS恰好捏住了我的舒适点。因此，我之后都将从MacOS上工作学习。</p><p>前一段时间我从公司实习离职，上交了公司发给我的MacBook(<del>停止薅羊毛</del>)，然而我又不想回到Windows，于是打算自己买一台MacBook。但是MacBook从2016年开始更换的蝶式键盘很让我恶心，姑且不说故障率高，触感实在太差劲了。尽管2020年新出的16寸Pro已经重回剪刀脚键盘了，但是我的需求是轻薄的13寸而不是16寸(<del>只是没钱而已</del>)。尽管听到业界的呼声说2020年的MacBook应该都会回到剪刀脚键盘，但由于2020年会换新模具，我也不想踩第一代模具的坑，因而暂且将目标定为2021年的MacBook，目前一年多买个二手过渡下就可以了。</p><p>1月份我在某宝平台上买了一台2014款8+256的二手MacBook Pro，即使前期做了许多选店和辨伪的功课，拿到手之后却依然中招，总是无理由黑屏然后再无法开机一天，十分坑爹。所幸可以十五天无理由退换货，就赶快退了。之前早就听说二手Mac的水很深，被坑一次之后更加确信。接着我做了更多的功课，学到了许多辨伪技巧，浏览了许多店铺，也算有点心得，之后要是有时间可以写出来分享给大家。</p><p>前几天经过慎重选择我又在某东平台上入手了一台2015款8+128的二手MacBook Pro。这次总算没什么问题，但比较有趣的一点是我买的8+128的，老板发给我的是8+256的，平白无故赚了128G的固态，只能说真的舒服了。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/home.jpeg" srcset="/img/loading.gif" alt=""></p><p>这是一个新的MacBook刚打开后的主页，接下来我要通过一系列的配置使其成为一个十分符合我开发习惯的机器，可供大家参考。</p><h2 id="系统篇"><a href="#系统篇" class="headerlink" title="系统篇"></a>系统篇</h2><h3 id="触屏板"><a href="#触屏板" class="headerlink" title="触屏板"></a>触屏板</h3><ul><li>2016年及之后的MacBook触屏板都有force touch的功能，即可以按压两次来实现更多的功能，但是我一直用不来这个功能，因此我的第一件事就是调整触摸屏板，首先先关掉force touch的功能，然后开启轻点来点按的点击方式，个人觉得这样才符合MacBook轻巧的特性嘛，每次都按下去多麻烦啊，现在手指轻轻一碰触摸板，就达到鼠标单击的顺滑效果。</li><li>除此以外，可以根据自己的习惯开启或关闭一些手势。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/touch_1.png" srcset="/img/loading.gif" alt=""><br><img src="http://q5ijnj5w7.bkt.clouddn.com/touch_2.png" srcset="/img/loading.gif" alt=""><br><img src="http://q5ijnj5w7.bkt.clouddn.com/touch_3.png" srcset="/img/loading.gif" alt=""></p><h3 id="键盘"><a href="#键盘" class="headerlink" title="键盘"></a>键盘</h3><ul><li>由于MacBook默认的重复前延迟和按键重复配置太慢，限制了程序员们优秀的打字速度，所以建议都调整到最快的速度。</li><li>可以在闲置5分钟后关闭键盘背光灯来省点电。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/input.png" srcset="/img/loading.gif" alt=""></p><h3 id="输入法"><a href="#输入法" class="headerlink" title="输入法"></a>输入法</h3><ul><li>由于MacBook默认的切换大小写的方式是长按Caps键，时间较慢需要等待，较为影响开发效率，建议关闭长按改为短按，配合极低的按键延迟会十分舒爽。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/input.png" srcset="/img/loading.gif" alt=""></p><h3 id="快速锁定屏幕"><a href="#快速锁定屏幕" class="headerlink" title="快速锁定屏幕"></a>快速锁定屏幕</h3><ul><li><p>如果你长时间离开电脑，最好锁定你的屏幕，以防止数据泄露。 那如何快速的锁定你的MacBook呢？ 答案是只需要一摸触摸板就可以了。</p><ul><li><p>打开系统偏好设置，点击桌面与屏幕保护程序图标，选择屏幕保护程序这个Tab，再点击触发角，在弹出的如下界面里面，右下角选择将显示器置入睡眠状态，再确定即可。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/screen_saver.png" srcset="/img/loading.gif" alt=""></p></li><li><p>再打开系统偏好设置，点击安全性与隐私图标，在通用Tab内，勾选为进入睡眠或开始屏幕保护程序立即要求输入密码。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/screen_saver.png" srcset="/img/loading.gif" alt=""></p></li></ul></li></ul><h2 id="开发环境篇"><a href="#开发环境篇" class="headerlink" title="开发环境篇"></a>开发环境篇</h2><h3 id="Xcode"><a href="#Xcode" class="headerlink" title="Xcode"></a>Xcode</h3><ul><li>首先安装Xcode，然后使用下面的命令安装Xcode command line tools，这将为我们安装很多终端下面常用的命令，将来很可能会使用到。<pre><code>  xcode-select --install</code></pre></li></ul><h3 id="Homebrew"><a href="#Homebrew" class="headerlink" title="Homebrew"></a>Homebrew</h3><ul><li>Homebrew是一款终端下的命令程序包管理器，安装非常简单，复制如下命令在终端下运行，按回车并输入密码后等待安装成功：<pre><code>  ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code></pre></li></ul><h3 id="iTerm2-Zsh-Z"><a href="#iTerm2-Zsh-Z" class="headerlink" title="iTerm2+Zsh+Z"></a>iTerm2+Zsh+Z</h3><ul><li>常用终端iTerm2+优秀Shell Zsh+扁平目录跳转命令Z，安装好之后开发十分舒适。具体安装可参考以下博客。<ul><li><a href="https://www.jianshu.com/p/a5f478a143dc" target="_blank" rel="noopener">MacOS 终端 iTerm2 并配置 Zsh</a></li></ul></li></ul><h3 id="快捷键迅速打开iTerm2"><a href="#快捷键迅速打开iTerm2" class="headerlink" title="快捷键迅速打开iTerm2"></a>快捷键迅速打开iTerm2</h3><ul><li>可以设置快捷键再Home页面输入 Command + , 直接打开iTerm2，这样就不用再去点击iTerm2了。<br><img src="http://q5ijnj5w7.bkt.clouddn.com/iTerm2_hotkey.png" srcset="/img/loading.gif" alt=""></li><li>可以设置iTerm2默认占满全屏，这样子快捷键打开之后就直接是一个全屏的iTerm2可以使用了<br><img src="http://q5ijnj5w7.bkt.clouddn.com/iTerm2_screen.png" srcset="/img/loading.gif" alt=""> </li></ul><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><ul><li>创建新的公钥私钥并与自己的Github账户连起来，这样就可以开始在Github遨游啦。</li></ul><h2 id="常用软件"><a href="#常用软件" class="headerlink" title="常用软件"></a>常用软件</h2><ul><li>网易云音乐</li><li>微信</li><li>QQ</li><li>SSR</li><li>Chrome</li><li>VScode</li><li>IDEA</li><li>Docker</li><li>…</li></ul>]]></content>
    
    
    <categories>
      
      <category>开发工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
