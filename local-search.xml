<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Raft 协议介绍</title>
    <link href="/raft/"/>
    <url>/raft/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h3><p>共识算法允许一组节点像一个整体一样一起工作，即使其中一些节点出现故障也能够继续工作下去。更详细点，可以认为每一个节点上都运行着一个状态机和一组日志。在客户端提交命令后，状态机负责执行命令并返回结果，同时还可能改变自己的状态；日志则记录了所有可能会影响到状态机的命令。任何一个处于初始状态的状态机都可以通过重新按顺序执行这组日志，来让自己恢复到最终状态。</p><p>共识算法常被用来确保每一个节点上的状态机一定都会按相同的顺序执行相同的命令， 并且最终会处于相同的状态。换句话说，可以理解为共识算法就是用来确保每个节点上的日志顺序都是一致的。（不过需要注意的是，只确保“提交给状态机的日志”顺序是一致的，而有些日志项可能只是暂时添加，尚未决定要提交给状态机）。正因为如此，共识算法在构建可容错的大规模分布式系统中扮演着重要的角色。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/raft_rsm.png" srcset="/img/loading.gif" alt=""></p><p>上图就是每个节点上的状态机，日志和同步模块与客户端交互的过程。</p><p>当然，实际使用系统中的共识算法一般满足以下特性：</p><ul><li>在非拜占庭条件（无恶意欺骗）下保证共识的一致性；</li><li>在多数节点存活时，保持可用性；</li><li>不依赖于时间，错误的时钟和高延迟只会导致可用性问题，而不会导致一致性问题；</li><li>在多数节点一致后就返回结果，而不会受到个别慢节点的影响。<br>（注：“多数”永远指的是配置文件中所有节点的多数，而不是存活节点的多数）<br>（注：非拜占庭条件，指的就是每一个节点都是诚实可信的，每一次信息的传递都是真实的且符合协议要求的，当节点无法满足协议所要求的条件时，就停止服务，节点仅会因为网络延迟或崩溃出现不一致，而不会有节点传递错误的数据或故意捏造假数据。）</li></ul><h3 id="Raft-的由来与宗旨"><a href="#Raft-的由来与宗旨" class="headerlink" title="Raft 的由来与宗旨"></a>Raft 的由来与宗旨</h3><p>众所周知，Paxos 是一个非常划时代的共识算法。在 Raft 出现之前的 10 年里，Paxos 几乎统治着共识算法这一领域：因为绝大多数共识算法的实现都是基于 Paxos 或者受其影响，同时 Paxos 也成为了教学领域里讲解共识问题时的示例。</p><p>但是不幸的是，尽管有很多工作都在尝试降低 Paxos 的复杂性，但是它依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。比如 Google Chubby 的论文就提到，因为 Paxos 的描述和现实差距太大，所以最终人们总会实现一套未经证实的类 Paxos 协议。</p><p>基于以上背景，Diego Ongaro 在就读博士期间，深入研究 Paxos 协议后提出了 Raft 协议，旨在提供更为易于理解的共识算法。Raft 的宗旨在于可实践性和可理解性，并且相比 Paxos 几乎没有牺牲多少性能。</p><blockquote><p>趣闻：<a href="https://groups.google.com/forum/#!topic/raft-dev/95rZqptGpmU" target="_blank" rel="noopener">Raft 名字的来源</a>。简而言之，其名字即来自于 R{eliable|plicated|dundant} And Fault-Tolerant， 也来自于这是一艘可以帮助你逃离 Paxos 小岛的救生筏（Raft）。</p></blockquote><h3 id="工业界的实现"><a href="#工业界的实现" class="headerlink" title="工业界的实现"></a>工业界的实现</h3><ul><li>Tidb</li><li>Consul</li><li>etcd</li><li>…</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>这一部分会简单介绍 Raft 的一些基本概念。若暂时没看懂并没有关系，后面会一一介绍清楚，带着问题耐心读完此博客即可。</p><h3 id="Raft-的节点类型"><a href="#Raft-的节点类型" class="headerlink" title="Raft 的节点类型"></a>Raft 的节点类型</h3><p>Raft 将所有节点分为三个身份：</p><ul><li>Leader：集群内最多只会有一个 Leader，负责发起心跳，响应客户端，创建日志，同步日志。</li><li>Candidate：Leader 选举过程中的临时角色，由 Follower 转化而来，发起投票参与竞选。</li><li>Follower：接受 Leader 的心跳和日志同步数据，投票给 Candidate。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/raft_state.png" srcset="/img/loading.gif" alt=""></p><p>上图可以看出 Raft 中节点状态之间变迁的条件。</p><p>在完整的论文和 etcd 实现中，其实又增加了几种中间状态：</p><ul><li>Learner(Non-Voting Member)：新加入的节点，不具有选举权，需要从 Leader 同步完数据后， 才能转变为 Follower。严格来说，Learner 并不算集群成员。</li><li>Pre-Candidate：刚刚发起竞选，还在等待 PreVote 结果的临时状态， 取决于 PreVote 的结果，可能进化为 Candidate，可能退化为 Follower。<br>（注：此两种节点状态的流程和作用后面章节会介绍，可先无视此两个状态）</li></ul><h3 id="Raft-的子问题"><a href="#Raft-的子问题" class="headerlink" title="Raft 的子问题"></a>Raft 的子问题</h3><p>Raft 将共识算法这个难解决的问题分解成了多个易解决，相对独立的子问题，这些问题都会在接下来的章节中进行介绍。</p><ul><li>选主：选出集群的 Leader 来统筹全局。</li><li>日志同步：Leader 负责从客户端接收请求，并且在集群中扩散同步。</li><li>安全：各节点间状态机的一致性保证。</li></ul><p>在完整的论文和 etcd 实现中，其实还有一些问题：</p><ul><li>配置变更：集群动态增删节点。</li><li>禅让：能够将 Leader 迅速转给另一个 Follower。</li><li>PreVote：在竞选开始时先进行一轮申请，若被允许再转变为 Candidate，这样有助于防止某些异常节点扰乱整个集群的正常工作。</li><li>…</li></ul><h3 id="Raft-的节点状态"><a href="#Raft-的节点状态" class="headerlink" title="Raft 的节点状态"></a>Raft 的节点状态</h3><p>每一个节点都应该有的持久化状态：</p><ul><li>currentTerm：当前任期。</li><li>votedFor：在当前 Term，给哪个节点投了票，值为 NULL 或 Candidate I。</li><li>log[]：已经 Commit 的日志。</li></ul><p>每一个节点都应该有的可以非持久化的状态：</p><ul><li>commitIndex：已提交的最大 Index。</li><li>lastApplied：已被状态机应用的最大 Index。<br>（注：这两个不需要持久化是因为状态机本身是非持久化的，而状态机的状态可以通过 log[] 来恢复）</li></ul><p>Leader 的非持久化状态：</p><ul><li>nextIndex[]：为每一个 Follower 保存的，应该发送的下一份 Entry Index；<br>初始化为 Last Index + 1。</li><li>matchIndex[]：：已确认的，已经同步到每一个 Follower 的 Entry Index<br>初始化为 0，单调递增。<br>（注：每次选举后，都应该立刻重新初始化）</li></ul><h3 id="Raft-的-Term-概念"><a href="#Raft-的-Term-概念" class="headerlink" title="Raft 的 Term 概念"></a>Raft 的 Term 概念</h3><p><img src="http://q5ijnj5w7.bkt.clouddn.com/raft_term.png" srcset="/img/loading.gif" alt=""></p><p>Raft 将时间划分成为任意不同长度的 Term。Term 用连续的数字进行表示。每一个 Term 的开始都是一次选举，一个或多个 Candidate 会试图成为 Leader。如果一个  Candidate 赢得了选举，它就会在该 Term 的剩余时间担任 Leader。在某些情况下，选票会被瓜分，有可能没有选出 Leader，那么，将会开始另一个 Term，并且立刻开始下一次选举。Raft 保证在给定的一个 Term 最多只有一个 Leader。</p><p>不同的服务器节点可能多次观察到 Term 之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个 Term 全程。Term 在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如过期的 Leader。</p><p>每个节点都会存储当前 Term 号，这一编号在整个时间内单调增长。当服务器之间通信的时候会交换当前 Term 号；如果一个服务器的当前 Term 号比其他人小，那么他会更新自己的 Term 到较大的 Term 值。如果一个 Candidate 或者 Leader 发现自己的 Term 过期了，那么他会立即退回 Follower。如果一个节点接收到一个包含过期 Term 号的请求，那么它会直接拒绝这个请求。</p><h3 id="Raft-的日志组成"><a href="#Raft-的日志组成" class="headerlink" title="Raft 的日志组成"></a>Raft 的日志组成</h3><ul><li><p>日志项（Entry）：Raft 中，将每一个事件都称为一个 Entry，每一个 Entry 都有一个表明它在 Log 中位置的 Index（之所以从 1 开始是为了方便 prevLogIndex 从 0 开始）。只有 Leader 可以创建 Entry。Entry 的内容为 &lt;term, index, cmd&gt;，其中 cmd 是可以应用到状态机的操作。被提交给状态机后，Entry 被称为是 Committed 的。</p></li><li><p>日志（Log）：由 Entry 构成的数组，只有 Leader 可以改变其他节点的日志。 Entry 总是先被添加进日志（写操作都应该立刻持久化），然后才发起共识请求，通过后才会被 Leader 提交给状态机。Follower 只能从 Leader 那获取到当前已经 Commit 日志的最大索引号，然后应用到自己的状态机。</p></li></ul><h3 id="Raft-的保证"><a href="#Raft-的保证" class="headerlink" title="Raft 的保证"></a>Raft 的保证</h3><ul><li>Election Safety：最多只会有一个 Leader。</li><li>Leader Append-Only：Leader 的日志是只增的。</li><li>Log Matching：如果两个节点的日志中有两个 Entry 有相同的 Index 和 Term，那么它们就是相同的 Entry。</li><li>Leader Completeness：一旦一个操作被提交了，那么在之后的 Term 中，该操作都会存在于日志中。</li><li>State Machine Safety：一致性，一旦一个节点应用了某个 Index 的操作到状态机，那么其他所有节点应用的该 Index 的操作都是一致的。</li></ul><h2 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h2><h2 id="Log-Replication-日志同步"><a href="#Log-Replication-日志同步" class="headerlink" title="Log Replication(日志同步)"></a>Log Replication(日志同步)</h2><h2 id="Configuration-Change-配置更改"><a href="#Configuration-Change-配置更改" class="headerlink" title="Configuration Change(配置更改)"></a>Configuration Change(配置更改)</h2><h2 id="Leadership-Transfer-禅让"><a href="#Leadership-Transfer-禅让" class="headerlink" title="Leadership Transfer(禅让)"></a>Leadership Transfer(禅让)</h2><h2 id="PreVote-提前投票"><a href="#PreVote-提前投票" class="headerlink" title="PreVote(提前投票)"></a>PreVote(提前投票)</h2><h2 id="Client-客户端"><a href="#Client-客户端" class="headerlink" title="Client(客户端)"></a>Client(客户端)</h2><h2 id="API-接口"><a href="#API-接口" class="headerlink" title="API(接口)"></a>API(接口)</h2><h2 id="Optimization-优化"><a href="#Optimization-优化" class="headerlink" title="Optimization(优化)"></a>Optimization(优化)</h2>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CAP 定理介绍</title>
    <link href="/cap-theory/"/>
    <url>/cap-theory/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在互联网行业飞速发展的 21 世纪，分布式系统正变得越来越重要，大型互联网公司如 Google, Amazon, MicroSoft, Alibaba, Tencent 等之所以被认为技术很厉害，很大程度上是因为其后台十分强悍，而这些后台一定是由若干个大的分布式系统组成的，因此理解分布式系统的运行原理对于程序员有非常重要的意义。</p><p>CAP 定理是分布式系统方向一个比较宽泛但很重要的基本定理，也可以作为理解分布式系统的起点。这篇博客将详细介绍 CAP 定理并简单证明，最后谈一谈 CAP 定理在工业界的应用。</p><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>2000年，柏克莱加州大学（University of California, Berkeley）的计算机科学家 Eric Brewer 在分布式计算原则研讨会（Symposium on Principles of Distributed Computing）提出，分布式系统有三个指标。</p><ul><li>Consistency</li><li>Availability</li><li>Partition tolerance</li></ul><p>它们的第一个字母分别是 C、A、P。</p><p>Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。</p><p>需要注意的是，尽管我们常说某个系统能够满足 CAP 属性中的 2 个，但并不是必须满足 2 个，许多系统只具有 0 或 1 个 CAP 属性。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h3><p>我们知道 ACID 中事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行前后，数据库都必须处于一致性状态。也就是说，事务的执行结果必须是使数据库从一个一致性状态转变到另一个一致性状态。</p><p>和 ACID 中的一致性不同，分布式环境中的一致性是指数据在多个副本之间是否能够保持一致的特性。</p><p>分布式系统中，数据一般会存在不同节点的副本中，如果对第一个节点的数据成功进行了更新操作，而第二个节点上的数据却没有得到相应更新，这时候读取第二个节点的数据依然是更新前的数据，即脏数据，这就是分布式系统数据不一致的情况。</p><p>在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都能读取到最新的值，那么这样的系统就被认为具有强一致性（或严格的一致性）。</p><h3 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h3><p>可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果，如果超过了这个时间范围，那么系统就被认为是不可用的。</p><p>“有限的时间内”是在系统的运行指标，不同系统会有差别。例如搜索引擎通常在 0.5 秒内需要给出用户检索结果。</p><p>”返回结果”是可用性的另一个重要指标，它要求系统完成对用户请求的处理后，返回一个正常的响应结果，要明确的反映出对请求处理的成功或失败。如果返回的结果是系统错误，比如”OutOfMemory”等报错信息，则认为此时系统是不可用的。</p><h3 id="Partition-Tolerance"><a href="#Partition-Tolerance" class="headerlink" title="Partition Tolerance"></a>Partition Tolerance</h3><p>一个分布式系统中，节点组成的网络本来应该是连通的。然而可能因为某些故障，使得有些节点之间不连通了，整个网络就分成了几块区域，而数据就散布在了这些不连通的区域中，这就叫分区。</p><p>当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。</p><p>提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项仍然能在其他区中读取，容忍性就提高了。然而，把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。</p><p>总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。</p><h2 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h2><h3 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h3><p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解 CAP 理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了 C 性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了 A 性质。除非两个节点可以互相通信，才能既保证 C 又保证 A，这又会导致丧失 P 性质。</p><h3 id="详细证明"><a href="#详细证明" class="headerlink" title="详细证明"></a>详细证明</h3><p><img src="http://q5ijnj5w7.bkt.clouddn.com/cap_base.png" srcset="/img/loading.gif" alt=""></p><p>我们现在有两个网络 N1 和 N2，每个网络中都存在一个服务用于从 db 获取数据，初始状态下，db 中存储的数据都是 V0。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/cap_p.png" srcset="/img/loading.gif" alt=""></p><p>正常情况下，在网络 N1 通过服务 A 更新 V0 到 V1，更新成功后发送消息 M 使 N2 的 db 中的 V0 变为 V1，此时我们通过服务 B 获取数据时，获取到 V1。</p><pre><code>此时满足 CA，没有分区故不满足 P。</code></pre><p><img src="http://q5ijnj5w7.bkt.clouddn.com/cap_withoutp.png" srcset="/img/loading.gif" alt=""></p><p>但是一旦发生了网络分区，此时我们通过服务 A 更新数据到 V1 后，由于网络错误，V1 值同步不到 N2 网络中去，此时我们调用服务 B 去请求数据的时候，我们必须从 C 和 A 选一个，如果选择 C，我们需要等到数据同步到 N2，但是从服务 B 获取数据肯定是失败了，失去了 A。如果选择 A，那么从 B 我们获取到的数据不是最新的，失去了 C。</p><pre><code>此时有分区故满足 P，CA 只能满足一个。</code></pre><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="取舍策略"><a href="#取舍策略" class="headerlink" title="取舍策略"></a>取舍策略</h3><h4 id="CP-without-A"><a href="#CP-without-A" class="headerlink" title="CP without A"></a>CP without A</h4><p>如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在 CAP 三者中保障 CP 而舍弃 A。</p><p>一个保证了 CP 而一个舍弃了 A 的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。</p><p>设计成 CP 的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成 CP 的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如 Redis、HBase 等，还有分布式系统中常用的 Zookeeper 也是在 CAP 三者之中选择优先保证 CP 的。</p><p>无论是像 Redis、HBase 这种分布式存储系统，还是像 Zookeeper 这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？</p><p>ZooKeeper 是个 CP（一致性+分区容错性）的，即任何时刻对 ZooKeeper 的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper 可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper 是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么 ZooKeeper 被设计成 CP 而不是 AP 特性的了。</p><h4 id="AP-wihtout-C"><a href="#AP-wihtout-C" class="headerlink" title="AP wihtout C"></a>AP wihtout C</h4><p>要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。</p><p>这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到 N 个 9，所以，对于很多业务系统来说，比如淘宝的购物，12306 的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。</p><p>你在 12306 买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。</p><p>但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。</p><p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到 N 个 9，即保证 P 和 A，舍弃 C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。</p><h4 id="CA-without-P"><a href="#CA-without-P" class="headerlink" title="CA without P"></a>CA without P</h4><p>这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃 P，意味着要舍弃分布式系统。那也就没有必要再讨论 CAP 理论了。这也是为什么在前面的 CAP 证明中，我们以系统满足 P 为前提论述了无法同时满足 C 和 A。</p><p>比如我们熟知的关系型数据库，如 Mysql 和 Oracle 就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把 P 也考虑进来。</p><p>其实，在 CAP 理论中。C，A，P 三者并不是平等的，CAP 之父在《Spanner，真时，CAP 理论》一文中写到：</p><blockquote><p>如果说 Spanner 真有什么特别之处，那就是谷歌的广域网。Google 通过建立私有网络以及强大的网络工程能力来保证 P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。</p></blockquote><p>从 Google 的经验中可以得到的结论是，一直以来我们可能被 CAP 理论蒙蔽了双眼，CAP 三者之间并不对称，C 和 A 不是 P 的原因（P 不能和 CA trade-off，CP 和 AP 中不存在 trade-off，trade-off 在 CA 之间）。提高一个系统的抗毁能力或者说提高 P（分区容忍能力）是通过提高基础设施的稳定性来获得的，而不是通过降低 C 和 A 来获得的。也就说牺牲 C 和 A 也不能提高 P。</p><p>所以，对于一个分布式系统来说。P 是一个基本要求，CAP 三者中，只能在 CA 两者之间做权衡，并且要想尽办法提升 P。P 提升的越好，CA 同时满足就越有可能。</p><h3 id="业界应用分析"><a href="#业界应用分析" class="headerlink" title="业界应用分析"></a>业界应用分析</h3><table><thead><tr><th>应用</th><th>类型</th><th>解释</th></tr></thead><tbody><tr><td>Mysql</td><td>CA</td><td>主从模式为 AP</td></tr><tr><td>Spanner</td><td>CA/CP</td><td>技术实现是 CP 但号称是 CA，宣称 CA 系统并不意味着 100％ 的可用性</td></tr><tr><td>分布式协议-Raft/ZAB/Paxos</td><td>CP</td><td>在分区后，对于 A，只有分区内节点大于 Quorum 才对外服务</td></tr><tr><td>分布式事务-2PC</td><td>CP</td><td>锁住资源,该资源其他请求阻塞</td></tr><tr><td>分布式事务-TCC</td><td>AP</td><td>最终一致性</td></tr><tr><td>分布式事务-最大努力尝试</td><td>AP</td><td>最终一致性</td></tr><tr><td>DNS服务</td><td>AP</td><td>最终一致性</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，因此分区容错性也就成为了一个分布式系统必然要面对的问题，那么就只能在 C 和 A 之间进行取舍。</p><p>对于某些安全性要求极高的项目，比如银行的转账系统，涉及到金钱的对于数据一致性不能做出一丝的让步，C 必须保证，出现网络故障的话，宁可停止服务，也不能冒着出错误的风险继续提供服务。</p><p>对于网站，DNS 服务等，其内容的实时性不是特别严格，则可以牺牲一定的一致性，保证最高的可用性是最好的选择。</p><p>个人认为，CAP 定理的核心在于，在网络分区的情况下，我们需要对 C 和 A 做出相应的妥协，我们不可能完全满足 CA，但是我们可以合理控制 C 和 A 之间的比例让我们的应用/中间件正常提供服务，同时也尽量提升基础设施的稳定性来保障 P。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>《Spanner，真时，CAP 理论》是 Google VP，CAP 理论之父在情人节当天撰写的，主要介绍了 Google 的 Spanner 数据库的真时（TrueTime）服务和 CA 特性，以及结合 CAP 理论的一些思考，建议阅读，阅读 Spanner 论文后阅读更佳。</p><ul><li><p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45855.pdf" target="_blank" rel="noopener">《Spanner，真时，CAP 理论》</a></p></li><li><p><a href="https://toutiao.io/posts/zdqrx0/preview" target="_blank" rel="noopener">《Spanner，真时，CAP 理论》中文</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iTerm2 快捷键介绍</title>
    <link href="/iTerm2-hotkeys/"/>
    <url>/iTerm2-hotkeys/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>iTerm2 是 MacOS 独有的终端工具，其有许多快捷键可以使用。为了便于开发并节约之后再次在搜索引擎上查询的时间成本，特写此博客以供自己日后查看。</p><h2 id="快捷键介绍"><a href="#快捷键介绍" class="headerlink" title="快捷键介绍"></a>快捷键介绍</h2><h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><ul><li>新建标签：Command + T</li><li>关闭标签：Command + W</li><li>切换标签：Command + 数字 或 Command + 左右方向键</li></ul><h3 id="分屏"><a href="#分屏" class="headerlink" title="分屏"></a>分屏</h3><ul><li>垂直分屏：Command + D</li><li>水平分屏：Command + Shift + D</li><li>切换屏幕：Command + Option + 方向键 或 Command + [ / ]</li></ul><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><ul><li>局部搜索(包含单个终端)：Command + F</li><li>全局搜索(包含所有Tab)：Command + Option + E</li><li>搜索历史指令：Ctrl + R</li></ul><h3 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h3><ul><li>查看历史命令：Command + ;</li><li>查看剪贴板历史：Command + Shift + H</li><li>上一条命令：Ctrl + P 或 上方向键</li></ul><h3 id="单行"><a href="#单行" class="headerlink" title="单行"></a>单行</h3><ul><li>光标到行首：Ctrl + A</li><li>光标到行尾：Ctrl + E</li><li>删除当前行：Ctrl + U</li><li>删除当前光标的字符：Ctrl + D</li><li>删除光标之前的字符：Ctrl + H</li><li>删除光标之前的单词：Ctrl + W</li><li>删除到文本末尾：Ctrl + K</li></ul><h3 id="内容大小"><a href="#内容大小" class="headerlink" title="内容大小"></a>内容大小</h3><ul><li>放大终端：Command + +</li><li>缩小终端：Command + - </li></ul><h3 id="常用快捷功能"><a href="#常用快捷功能" class="headerlink" title="常用快捷功能"></a>常用快捷功能</h3><ul><li>清屏：Command + R 或 Crtl + L</li><li>切换全屏：Command + Enter</li><li>选中即复制：在 iTerm2 界面，选择了一行就已经复制了</li></ul>]]></content>
    
    
    <categories>
      
      <category>开发工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的高效 Macbook 工作环境配置</title>
    <link href="/mac-configuration/"/>
    <url>/mac-configuration/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>工欲善其事，必先利其器，工具永远都是用来解决问题的，没必要为了工具而工具，一切工具都是为了能快速准确的完成工作和学习任务而服务。</p><p>我呢，在使用了 Windows，Ubuntu 和 MacOS 三种操作系统之后。结合种种体验和踩坑，最终还是觉得 MacOS 更舒适一点。每个人都有每个人的看法，每个人都有每个人的舒适点，MacOS 恰好捏住了我的舒适点。因此，我之后都将从 MacOS 上工作学习。</p><p>前一段时间我从公司实习离职，上交了公司发给我的 MacBook（<del>停止薅羊毛</del>），然而我又不想回到 Windows，于是打算自己买一台 MacBook。但是 MacBook 从 2016 年开始更换的蝶式键盘很让我恶心，姑且不说故障率高，触感实在太差劲了。尽管 2020 年新出的 16 寸 Pro 已经重回剪刀脚键盘了，但是我的需求是轻薄的 13 寸而不是 16 寸（<del>只是没钱而已</del>）。尽管听到业界的呼声说 2020 年的 MacBook 应该都会回到剪刀脚键盘，但由于 2020 年会换新模具，我也不想踩第一代模具的坑，因而暂且将目标定为 2021 年的 MacBook，目前一年多买个二手过渡下就可以了。</p><p>1 月份我在某宝平台上买了一台 2014 款 8+256 的二手 MacBook Pro，即使前期做了许多选店和辨伪的功课，拿到手之后却依然中招，总是无理由黑屏然后再无法开机一天，十分坑爹。所幸可以十五天无理由退换货，就赶快退了。之前早就听说二手 Mac 的水很深，被坑一次之后更加确信。接着我做了更多的功课，学到了许多辨伪技巧，浏览了许多店铺，也算有点心得，之后要是有时间可以写出来分享给大家。</p><p>前几天经过慎重选择我又在某东平台上入手了一台 2015 款 8+128 的二手 MacBook Pro。这次总算没什么问题，但比较有趣的一点是我买的 8+128 的，老板发给我的是 8+256 的，平白无故赚了 128G 的固态，只能说真的舒服了。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/home.jpeg" srcset="/img/loading.gif" alt=""></p><p>这是一个新的 MacBook 刚打开后的主页，接下来我要通过一系列的配置使其成为一个十分符合我开发习惯的机器，可供大家参考。</p><h2 id="系统篇"><a href="#系统篇" class="headerlink" title="系统篇"></a>系统篇</h2><h3 id="触屏板"><a href="#触屏板" class="headerlink" title="触屏板"></a>触屏板</h3><ul><li>2016 年及之后的 MacBook 触屏板都有 Force touch 的功能，即可以按压两次来实现更多的功能，但是我一直用不来这个功能，因此我的第一件事就是调整触摸屏板，首先先关掉 Force touch 的功能，然后开启轻点来点按的点击方式，个人觉得这样才符合 MacBook 轻巧的特性嘛，每次都按下去多麻烦啊，现在手指轻轻一碰触摸板，就达到鼠标单击的顺滑效果。</li><li>除此以外，可以根据自己的习惯开启或关闭一些手势。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/touch_1.png" srcset="/img/loading.gif" alt=""><br><img src="http://q5ijnj5w7.bkt.clouddn.com/touch_2.png" srcset="/img/loading.gif" alt=""><br><img src="http://q5ijnj5w7.bkt.clouddn.com/touch_3.png" srcset="/img/loading.gif" alt=""></p><h3 id="键盘"><a href="#键盘" class="headerlink" title="键盘"></a>键盘</h3><ul><li>由于 MacBook 默认的重复前延迟和按键重复配置太慢，限制了程序员们优秀的打字速度，所以建议都调整到最快的速度。</li><li>可以在闲置 5 分钟后关闭键盘背光灯来省点电。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/input.png" srcset="/img/loading.gif" alt=""></p><h3 id="输入法"><a href="#输入法" class="headerlink" title="输入法"></a>输入法</h3><ul><li>由于 MacBook 默认的切换大小写的方式是长按 Caps 键，时间较慢需要等待，较为影响开发效率，建议关闭长按改为短按，配合极低的按键延迟会十分舒爽。</li></ul><p><img src="http://q5ijnj5w7.bkt.clouddn.com/input.png" srcset="/img/loading.gif" alt=""></p><h3 id="快速锁定屏幕"><a href="#快速锁定屏幕" class="headerlink" title="快速锁定屏幕"></a>快速锁定屏幕</h3><ul><li><p>如果你长时间离开电脑，最好锁定你的屏幕，以防止数据泄露。 那如何快速的锁定你的 MacBook 呢？ 答案是只需要一摸触摸板就可以了。</p><ul><li><p>打开系统偏好设置，点击桌面与屏幕保护程序图标，选择屏幕保护程序这个 Tab，再点击触发角，在弹出的如下界面里面，右下角选择将显示器置入睡眠状态，再确定即可。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/screen_saver.png" srcset="/img/loading.gif" alt=""></p></li><li><p>再打开系统偏好设置，点击安全性与隐私图标，在通用 Tab 内，勾选为进入睡眠或开始屏幕保护程序立即要求输入密码。</p><p><img src="http://q5ijnj5w7.bkt.clouddn.com/screen_saver.png" srcset="/img/loading.gif" alt=""></p></li></ul></li></ul><h2 id="开发环境篇"><a href="#开发环境篇" class="headerlink" title="开发环境篇"></a>开发环境篇</h2><h3 id="Xcode"><a href="#Xcode" class="headerlink" title="Xcode"></a>Xcode</h3><ul><li>首先安装 Xcode，然后使用下面的命令安装 Xcode command line tools，这将为我们安装很多终端下面常用的命令，将来很可能会使用到。<pre><code>  xcode-select --install</code></pre></li></ul><h3 id="Homebrew"><a href="#Homebrew" class="headerlink" title="Homebrew"></a>Homebrew</h3><ul><li>Homebrew 是一款终端下的命令程序包管理器，安装非常简单，复制如下命令在终端下运行，按回车并输入密码后等待安装成功：<pre><code>  ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code></pre></li></ul><h3 id="iTerm2-Zsh-Z"><a href="#iTerm2-Zsh-Z" class="headerlink" title="iTerm2 + Zsh + Z"></a>iTerm2 + Zsh + Z</h3><ul><li>常用终端 iTerm2 + 优秀 Shell Zsh + 扁平目录跳转命令 Z，安装好之后开发十分舒适。具体安装可参考以下博客。<ul><li><a href="https://www.jianshu.com/p/a5f478a143dc" target="_blank" rel="noopener">MacOS 终端 iTerm2 并配置 Zsh</a></li></ul></li></ul><h3 id="快捷键迅速打开-iTerm2"><a href="#快捷键迅速打开-iTerm2" class="headerlink" title="快捷键迅速打开 iTerm2"></a>快捷键迅速打开 iTerm2</h3><ul><li>可以设置快捷键再 Home 页面输入 Command + , 直接打开 iTerm2，这样就不用再去点击 iTerm2 了。<br><img src="http://q5ijnj5w7.bkt.clouddn.com/iTerm2_hotkey.png" srcset="/img/loading.gif" alt=""></li><li>可以设置 iTerm2 默认占满全屏，这样子快捷键打开之后就直接是一个全屏的 iTerm2 可以使用了<br><img src="http://q5ijnj5w7.bkt.clouddn.com/iTerm2_screen.png" srcset="/img/loading.gif" alt=""> </li></ul><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><ul><li>创建新的公钥私钥并与自己的 Github 账户连起来，这样就可以开始在 Github 遨游啦。</li></ul><h2 id="常用软件"><a href="#常用软件" class="headerlink" title="常用软件"></a>常用软件</h2><ul><li>网易云音乐</li><li>微信</li><li>QQ</li><li>SSR</li><li>Chrome</li><li>VScode</li><li>IDEA</li><li>Docker</li><li>…</li></ul>]]></content>
    
    
    <categories>
      
      <category>开发工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
